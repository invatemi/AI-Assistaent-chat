Тестовое задание: High-Performance AI Chat Interface
1. Контекст
Необходимо реализовать интерфейс чата для LLM-платформы. 
Основная сложность — работа с большими объемами текстовых данных (History > 5MB) 
и высокоскоростным потоковым (streaming) обновлением ответов, без блокировки UI.

2. Стек технологий
Core: React 18+, TypeScript.
State Management: Zustand.
Styling: Tailwind CSS.
Build: Vite.

3. Задача
Создать SPA, эмулирующее общение с ИИ.

Функциональные требования:
Список сообщений: Отображение истории чата. В истории 
может быть 100+ сообщений, некоторые из которых очень 
длинные (лонгриды по 3-5к токенов).

Эмуляция стриминга: По нажатию кнопки "Generate" должно 
начинаться "потоковое" добавление текста в последнее сообщение.

Скорость: Эмулировать экстремально быструю генерацию (например, приход чанков каждые 10-20мс).

Объем: Сгенерировать "на лету" около 10,000 слов в одном сообщении.

Управление состоянием: Все сообщения должны храниться в Zustand store.

UI/UX:
Автоскролл к низу при генерации (с возможностью отключить, если пользователь начал скроллить вверх).
Кнопка "Stop Generating".

Технические требования:
Zero UI Freezes: Интерфейс должен оставаться отзывчивым (60 FPS) во время генерации.
Ввод в инпут или скролл не должны лагать, пока идет стриминг текста.

Рендеринг: Реализовать эффективный рендеринг. Браузер не должен "падать" от DOM-дерева размером 5МБ.

Подсказка: Ожидается использование виртуализации (windowing) или умной мемоизации, либо гибридного 
подхода (рендерить Markdown только для видимой области).

Markdown: Поддержка простейшего Markdown (хотя бы Code Blocks и Bold), так 
как это чат для разработчиков. Парсинг Markdown не должен блокировать основной 
поток (Main Thread) при больших объемах текста.

4. Входные данные (Mock)
Кандидат должен написать простой генератор текста. 
Пример: Функция, которая в цикле setInterval пушит в Zustand store куски текста 
(Lorem Ipsum или код) до тех пор, пока не наберется заданный объем.